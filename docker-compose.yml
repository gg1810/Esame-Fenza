services:
  # DATABASE: MongoDB
  mongodb:
    image: mongo:latest
    container_name: cinematch_db
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  # KAFKA (KRaft mode - no Zookeeper required)
  kafka:
    image: apache/kafka:3.7.0
    container_name: cinematch_kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:29092,CONTROLLER://:9093,EXTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"

  # BACKEND: Python (FastAPI)
  backend:
    build: ./backend
    container_name: cinematch_backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./Dati-prova-letterbox:/data
      - ./Dati_film:/data/catalog
    environment:
      - MONGODB_URL=mongodb://mongodb:27017
      - MOVIES_CSV_PATH=/data/catalog/movies_final.csv
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    depends_on:
      - mongodb
      - kafka

  # FRONTEND: React (Vite)
  frontend:
    build: ./cinematch-dashboard
    container_name: cinematch_frontend
    ports:
      - "5173:5173"
    volumes:
      - ./cinematch-dashboard:/app
      - /app/node_modules
    depends_on:
      - backend

  # SPARK STATS PROCESSOR: Elaborazione streaming eventi film
  spark-stats-processor:
    image: apache/spark:3.4.0
    container_name: spark_stats_processor
    volumes:
      - ./backend:/app
      - spark_checkpoints:/tmp/spark-checkpoints
      - spark_ivy2:/tmp/.ivy2
    working_dir: /app
    user: root
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - MONGODB_URL=mongodb://mongodb:27017
      - HOME=/tmp
      - SPARK_HOME=/opt/spark
    entrypoint: [ "/bin/bash", "-c" ]
    command:
      - |
        pip install pymongo kafka-python pytz --quiet
        /opt/spark/bin/spark-submit \
          --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.mongodb.spark:mongo-spark-connector_2.12:10.2.0 \
          --conf spark.driver.extraJavaOptions=-Divy.home=/tmp/.ivy2 \
          --master local[2] \
          spark_stats_processor.py
    depends_on:
      - kafka
      - mongodb
    restart: on-failure

  # GRAFANA: Dashboard Analytics (usa Infinity plugin)
  grafana:
    image: grafana/grafana:latest
    container_name: cinematch_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ALLOW_EMBEDDING=true
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_INSTALL_PLUGINS=yesoreyeram-infinity-datasource
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - backend

  # OLLAMA: AI per generazione Quiz
  ollama:
    image: ollama/ollama:latest
    container_name: cinematch_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

volumes:
  mongo_data:
  grafana_data:
  ollama_data:
  spark_checkpoints:
  kafka_data:
  spark_ivy2: